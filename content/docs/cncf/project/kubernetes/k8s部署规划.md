---
date: '2025-11-06T07:48:55+08:00'
title: 'K8s部署规划'
tags: 'K8s部署规划'
---

# 介绍

这里汇总了部署k8s时的一些注意事项,主要是稳定性和维护成本的考虑---仅个人观点

### 集群规模

官方建议见: <https://kubernetes.io/docs/setup/best-practices/cluster-large/>
 
1. 单个节点不超过 110 个pod
2. 单集群节点数量不超过 5000 个(个人建议不超过 500。但如果是单节点 pod 数量很少，比如 AI 集群，每个节点 10 以内的 pod，则节点可以更大)
3. 单集群 pod 数量不超过 15 万(个人建议不超过 6 万)
4. 单 ns 下 pod (其他资源类似)数量(个人建议不超过1千。因为 k8s 的查询是没有分页机制的，如果比较大，查询一次资源就是 1 秒以上返回--当然可以通过优化比如加缓存等解决)

注意:

Q: 为什么不是一个超大集群,这样就只需要维护一个集群即可?
A: 集群越大,维护难度越大,各组件性能瓶颈问题就越多,有大量的高难度维护工作

  比如:

  1. 集群达到一定程度, etcd 就扛不住了,需要拆分多个 etcd,比如
      字节的方案: 自研了代替 etcd 的存储组件 <https://github.com/kubewharf/kubebrain/blob/main/docs/design_in_detail_cn.md>
      蚂蚁的方案: 分多个etcd存储 <https://www.sofastack.tech/blog/ant-massive-sigma-cluster-etcd-splitting-in-practice/>
      阿里: 修改了etcd代码 <https://zhuanlan.zhihu.com/p/657824957>
  2. apiserver 就很容易打爆了,仅仅是大量节点上kubelet和apiservice的流量就很大,再加上很多operator等,这个时候就需要扩容,限流等规划,比如
      字节的方案: 自研KubeGateway组件 KubeGateway <https://zhuanlan.zhihu.com/p/546398348>
      阿里的: <https://zhuanlan.zhihu.com/p/657824957>
  3. scheduler 调度器已经不行了,大规模的集群下,pod 创建的并发数量自然也就上来了,默认的调度器是一个一个pod调度的,这个会导致pod调度时间会等待很久很久,
      社区也有一些解决方案: <https://kubernetes.io/docs/concepts/scheduling-eviction/scheduler-perf-tuning/>
      其他大厂一般是自研调度器了: <https://zhuanlan.zhihu.com/p/563944955>
  4. controller 和 opeartor, 这里组件的瓶颈主要是 list watch 机制导致的，这个机制的原理是把需要的资源一次性缓存到自己的内存里面,然后 watch 变化持续更新缓存,但当集群比较大时，就会导致启动的时候创建缓存会很慢（分钟级别），内存占用会非常高，资源（比如 pod 上十万，百万）变化数量也会很大,不一定能处理的过来（因为控制器也是一个一个的对变化事件进行处理）
  5. 网络: 看你选择的网络方案,比如 calico ,每个机器上的网络规则等就会非常非常多了,一般: 推荐走 IAAS 的网络,比如 macVlan 等,依靠底层 iaas 网络能力进行支撑
  6. 爆炸班级: 出现故障后,影响的pod就比较多,影响面比较广

### 集群部署策略(什么时候建新集群)

什么时候应该新建集群还是用老集群, 这里并没有统一的规范,这里只是一些针对稳定性,维护性等可以参考的点

拆分的好处: 集群小稳定性高,每个集群相对业务比较类似管理方便
合并的好处: 集群少不需要维护很多集群,资源利用率更高

1. 如果你的网络区是隔离的,则建议每个网络区部署一个集群,比如银行等,会划分互联网区和内网区等,则推荐每个网络区一个集群
2. 如果你的业务需要满足多活,比如同城双活,两地三中心,多活等架构,则推荐根据高可用要求,每个机房（或可用区）建1-2个集群,避免集群层面存在单点故障
3. 如果你的多个机房直接网络延迟比较高,比如大于100ms,则推荐分别建设集群
4. 如果你的集群已经达到了规模,则推荐按业务等维度进行拆分集群,比如可以按电商系统,内部系统拆分两个集群
5. 如果你的业务比较特殊,推荐建设独立集群,比如AI的训练和推理集群,则推荐和业务集群分开单独建设集群

### 网络选型

1. calico: 一般的场景,推荐calico 直通模式, 架构简单, 实现原理就是linux上route表, 一般的网络工程师或linux 运维同学 稍加学习就能完成日常的维护和应急的手动处理
2. cilium: 高性能,基于内核ebpf 实现, 功能强大,支持四层,七层,网关,可以代替kube-proxy,观测能力强大。如果有能力维护的话推荐
3. macvlan: 金融客户对ip 审计等要求比较高,集群规模比较大的场景, 这样网络更像虚拟机的网络,可以复用现有的底层网络管理平台，工具，规范(强烈推荐道客开源的spiderpool: https://github.com/spidernet-io/spiderpool ,经过了大规模金融客户生产落地,稳定并且功能丰富)

### 节点配置

因为单节点不推荐超过110个pod(这里的原因是 110个pod,容器数量已经是220多个了, 进程数量,连接数都已经比较大了, linux 的进程切换等可能已经比较影响性能了)
所以单机的配置并不是越大越好--不然会资源浪费
所以可以根据你的业务场景进行估算
大概的估算逻辑是: 机器资源=(单个pod 平均资源* 110 )/超卖系数(超卖50%，也就是申请1.5core,只预留1core)/ 系统资源预留比例 ( 也就是正常最高峰时机器资源最大占用比例,比如0.8代表机器最大占用到80%)
比如目前大部分的业务 pod 还是java,一般会规范内存和cpu比例为1:2或1:4, 比如1core4G, 4core 8G

机器推荐的资源=(1core4G（假设大部分pod最小pod是这个） *110)/ 超卖系数是1.5(超卖50%，也就是申请1.5core,只预留1core)/ 系统资源预留0.8( 也就是正常最高业务也就是使用到80%) = (1*110/1.5/0.8)=92core,(4*110/1.5/0.8)=367G, 采购 92core512G 类型的物理机器

只是举例，仅供参考，要根据实际真实情况估算，比如中间件集群，中间件需要大量的内存作为缓存等等